{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv(r'S:\\fake_news_classifier\\train.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Drop nan \r\n",
    "df = df.dropna()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# independent and dependent features\r\n",
    "X = df.drop('label',axis=1)\r\n",
    "y = df['label']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.layers import Embedding         # for word embedding\r\n",
    "# for making all vectors of same length (pre or post padding: include 0 in front or end)\r\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.preprocessing.text import one_hot\r\n",
    "from tensorflow.keras.layers import  LSTM\r\n",
    "from tensorflow.keras.layers import Dense"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Vocabulary Size\r\n",
    "voc_size = 8000"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# One-Hot Representation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "message = X.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "message.reset_index(inplace = True)  # since we have dropped nan values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import nltk\r\n",
    "import re\r\n",
    "from nltk.corpus import stopwords"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nltk.download('stopwords')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Data Preprocessing\r\n",
    "from nltk.stem.porter import PorterStemmer\r\n",
    "ps = PorterStemmer()\r\n",
    "corpus = []\r\n",
    "for i in range(0, len(message)):\r\n",
    "    print(i)\r\n",
    "    # substituting everything except a-z and A-Z with '(space)' in message[title]\r\n",
    "    review = re.sub('[^a-zA-Z]', ' ', message['title'][i])\r\n",
    "    review = review.lower()\r\n",
    "    review = review.split()  # applied to remove Stopwords(not necessary words)\r\n",
    "    \r\n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\r\n",
    "    review = ' '.join(review)\r\n",
    "    corpus.append(review)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corpus"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "onehot_rep = [one_hot(words, voc_size)for words in corpus]\r\n",
    "onehot_rep"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Embedding Representation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sen_len = 20\r\n",
    "embedded_doc = pad_sequences(onehot_rep, padding='post', maxlen=sen_len)\r\n",
    "print(embedded_doc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(embedded_doc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embed_vector_features = 50\r\n",
    "model=Sequential()\r\n",
    "model.add(Embedding(voc_size, embed_vector_features, input_length=sen_len))\r\n",
    "model.add(LSTM(100))\r\n",
    "model.add(Dense(1, activation='sigmoid'))\r\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
    "print(model.summary())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "X_final = np.array(embedded_doc)\r\n",
    "y_final = np.array(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_final.shape, y_final.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_final, y_final, test_size=0.25, random_state= 42)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=60)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adding Dropout"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.layers import Dropout\r\n",
    "## Creating model\r\n",
    "embedding_vector_features=40\r\n",
    "model=Sequential()\r\n",
    "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\r\n",
    "model.add(Dropout(0.3))\r\n",
    "model.add(LSTM(100))\r\n",
    "model.add(Dropout(0.3))\r\n",
    "model.add(Dense(1,activation='sigmoid'))\r\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Performance matrix and accuracy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred=model.predict_classes(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import confusion_matrix\r\n",
    "confusion_matrix(y_test,y_pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import accuracy_score\r\n",
    "accuracy_score(y_test,y_pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('gpu': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "85aa16142240ac8ebf1a86d30f12849a0d8917b454ec11c400ebe33de0ce5335"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
